{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce54f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4568bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef7d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b7fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vector_store = Chroma(\n",
    "    embedding_function=OpenAIEmbeddings(model='text-embedding-3-large'),\n",
    "    collection_name='income_tax_collections',\n",
    "    persist_directory='./income_tax_collections'\n",
    ")\n",
    "retriever = vector_store.as_retriever(search_kwargs={'k': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c077e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    context: list\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc86c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "tavily_search_tool = TavilySearchResults(\n",
    "    max_results=3,\n",
    "    search_depth=\"advanced\",\n",
    "    include_answer=True,\n",
    "    include_raw_content=True,\n",
    "    include_images=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb01427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    'web_search' Node\n",
    "    : 주어진 state를 기반으로 웹 검색을 수행한다.\n",
    "\n",
    "    Args:\n",
    "        - state(AgentState): 사용자의 질문을 포함한 에이전트의 현재 state\n",
    "\n",
    "    Returns:\n",
    "        - AgentState: 웹 검색 결과가 추가된 state\n",
    "    \"\"\"\n",
    "    \n",
    "    query = state['query']\n",
    "    \n",
    "    # 웹 검색 도구 활용\n",
    "    results = tavily_search_tool.invoke(query)\n",
    "    \n",
    "    return {'context': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feddac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt = client.pull_prompt(\"rlm/rag-prompt\", include_model=True)\n",
    "\n",
    "def web_generate(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    'web_generate' Node\n",
    "    : 사용자의 질문과 웹 검색된 문서를 기반으로 응답을 생성한다.\n",
    "\n",
    "    Args:\n",
    "        - state(AgentState): 사용자의 질문과 검색된 문서를 포함한 에이전트의 현재 state\n",
    "\n",
    "    Returns:\n",
    "        - AgentState: 생성된 응답이 추가된 state\n",
    "    \"\"\"\n",
    "    \n",
    "    query = state['query']\n",
    "    context = state['context']\n",
    "    \n",
    "    rag_chain = rag_prompt | llm\n",
    "    ai_message = rag_chain.invoke({'question': query, 'context': context})\n",
    "    \n",
    "    return {'answer': ai_message}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90018baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_generate(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    'basic_generate' Node\n",
    "    : 사용자의 질문에 대한 응답을 생성한다.\n",
    "\n",
    "    Args:\n",
    "        - state(AgentState): 사용자의 질문을 포함한 에이전트의 현재 state\n",
    "\n",
    "    Returns:\n",
    "        - AgentState: 생성된 응답이 추가된 state\n",
    "    \"\"\"\n",
    "    \n",
    "    query = state['query']\n",
    "    \n",
    "    # LLM에게 직접 질문\n",
    "    ai_message = llm.invoke(query)\n",
    "    \n",
    "    return {'answer': ai_message}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Router(BaseModel):\n",
    "    target: Literal['vector_store', 'llm', 'web_search'] = Field(\n",
    "        description=\"The target for the query to answer\"\n",
    "    )\n",
    "    \n",
    "structured_llm = llm.with_structured_output(Router)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb8845",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_system_prompt = \"\"\"\n",
    "You are an expert at routing a user's question to 'vector_store', 'llm', or 'web_search'.\n",
    "\n",
    "if you think the question is simple enough use 'llm'.\n",
    "if you think you need to search the web to answer the question use 'web_search'.\n",
    "\n",
    "- 'vector_store' contains information about income tax up to December 2024.\n",
    "\"\"\"\n",
    "\n",
    "route_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', route_system_prompt),\n",
    "    ('user', '{query}')\n",
    "])\n",
    "\n",
    "def route(state: AgentState) -> Literal['vector_store', 'llm', 'web_search']:\n",
    "    \"\"\"\n",
    "    'route' Node\n",
    "    : 사용자 질문의 적절한 경로를 결정한다.\n",
    "\n",
    "    Args:\n",
    "        - state(AgentState): 사용자의 질문을 포함한 에이전트의 현재 state\n",
    "\n",
    "    Returns:\n",
    "        - Literal['vector_store', 'llm', 'web_search']: 질문을 처리하기 위한 경로를 나타내는 문자열\n",
    "    \"\"\"\n",
    "    \n",
    "    query = state['query']\n",
    "    \n",
    "    # 라우터 체인\n",
    "    route_chain = route_prompt | structured_llm\n",
    "    ai_message = route_chain.invoke({'query': query})\n",
    "    \n",
    "    print(f\"target=={ai_message.target}\")\n",
    "    \n",
    "    return ai_message.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364ca3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from graph.income_tax_graph import graph as income_tax_graph\n",
    "\n",
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "# nodes\n",
    "graph_builder.add_node('web_search', web_search)\n",
    "graph_builder.add_node('web_generate', web_generate)\n",
    "graph_builder.add_node('basic_generate', basic_generate)\n",
    "graph_builder.add_node('income_tax_agent', income_tax_graph)\n",
    "\n",
    "# edges\n",
    "graph_builder.add_conditional_edges(\n",
    "    START,\n",
    "    route,\n",
    "    {\n",
    "        'vector_store': 'income_tax_agent',\n",
    "        'llm': 'basic_generate',\n",
    "        'web_search': 'web_search'\n",
    "    }\n",
    ")\n",
    "graph_builder.add_edge('web_search', 'web_generate')\n",
    "graph_builder.add_edge('web_generate', END)\n",
    "graph_builder.add_edge('basic_generate', END)\n",
    "graph_builder.add_edge('income_tax_agent', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ead9e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63618469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90692871",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"연봉 5천만원인 거주자가 납부해야 하는 소득세는 얼마인가요?\"\n",
    "query2 = \"군자역 맛집을 알려주세요.\"\n",
    "query3 = \"대한민국의 수도는 어디인가요?\"\n",
    "initial_state = {'query': query1}\n",
    "\n",
    "graph.invoke(initial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inflearn-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
