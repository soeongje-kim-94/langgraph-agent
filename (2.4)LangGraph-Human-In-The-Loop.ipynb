{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9549c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9187d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85abc3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vector_store = Chroma(\n",
    "    embedding_function=OpenAIEmbeddings(model='text-embedding-3-large'),\n",
    "    collection_name='real_estate_tax_collections',\n",
    "    persist_directory='./real_estate_tax_collections'\n",
    ")\n",
    "retriever = vector_store.as_retriever(search_kwargs={'k': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8026e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever=retriever,\n",
    "    name='real_estate_tax_retriever',\n",
    "    description='Contains information about real estate tax up to December 2024'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a5494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tavily_search_tool = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic=\"general\",\n",
    "    # include_answer=False,\n",
    "    # include_raw_content=False,\n",
    "    # include_images=False,\n",
    "    # include_image_descriptions=False,\n",
    "    # search_depth=\"basic\",\n",
    "    # time_range=\"day\",\n",
    "    # include_domains=None,\n",
    "    # exclude_domains=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab2bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ArxivQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "\n",
    "arxiv_tool = ArxivQueryRun(api_wrapper=ArxivAPIWrapper(top_k_results=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c70e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_community import GmailToolkit\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Can review scopes here https://developers.google.com/gmail/api/auth/scopes\n",
    "# For instance, readonly scope is 'https://www.googleapis.com/auth/gmail.readonly'\n",
    "SCOPES = [\n",
    "    \"https://www.googleapis.com/auth/gmail.compose\",\n",
    "    \"https://www.googleapis.com/auth/gmail.send\"\n",
    "]\n",
    "\n",
    "flow = InstalledAppFlow.from_client_secrets_file(\n",
    "    \"./google/gmail_credentials.json\",\n",
    "    SCOPES,\n",
    ")\n",
    "credentials = flow.run_local_server(port=0)\n",
    "api_resource = build(\"gmail\", \"v1\", credentials=credentials)\n",
    "gmail_toolkit = GmailToolkit(api_resource=api_resource)\n",
    "gmail_tool_list = gmail_toolkit.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac3a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_list = [retriever_tool, tavily_search_tool, arxiv_tool]\n",
    "tool_list += gmail_tool_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95656a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_node = ToolNode(tool_list)\n",
    "llm_with_tools = llm.bind_tools(tool_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bdb7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class AgentState(MessagesState):\n",
    "    summary: str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d955787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "def human_review(state: AgentState) -> Command[Literal['tools', 'agent']]:\n",
    "    \"\"\"\n",
    "    'human_review' Node\n",
    "    : LLM의 도구 호출에 대해 사용자의 검토를 요청한다.\n",
    "\n",
    "    Args:\n",
    "        - state(AgentState): 메시지 상태와 요약을 포함하는 state\n",
    "\n",
    "    Returns:\n",
    "        - Command[Literal['tools', 'agent']: 다음 node로 이동하기 위한 Command\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = state['messages']\n",
    "    last_ai_message = messages[-1]\n",
    "    last_tool_call = last_ai_message.tool_calls[-1]\n",
    "    \n",
    "    # review\n",
    "    human_review = interrupt(\n",
    "        {\n",
    "            'question': '이렇게 진행하면 될까요?',\n",
    "            'tool_call': last_tool_call\n",
    "        }\n",
    "    )\n",
    "    review_action = human_review['action']\n",
    "    review_data = human_review.get('data', None)\n",
    "    \n",
    "    ## 에이전트의 판단이 맞다면, 도구를 사용하기 위해 아무것도 수정하지 않고 `tools` 노드로 이동\n",
    "    if review_action == 'continue':\n",
    "        return Command(goto='tools')\n",
    "    \n",
    "    ## 도구를 더 효율적으로 사용하기 위해 AIMessage의 `tool_calls` 필드를 업데이트\n",
    "    if review_action == 'update_args':\n",
    "        update_ai_message = {\n",
    "            'id': last_ai_message.id,\n",
    "            'role': 'ai',\n",
    "            'content': last_ai_message.content,\n",
    "            'tool_calls': [\n",
    "                {\n",
    "                    'id': last_tool_call['id'],\n",
    "                    'name': last_tool_call['name'],\n",
    "                    'args': review_data\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        return Command(goto='tools', update={'messages': [update_ai_message]})\n",
    "    \n",
    "    # 다른 도구를 사용하기 위해 `ToolMessage`를 업데이트\n",
    "    if review_action == 'update_tool':\n",
    "        updated_tool_message = {\n",
    "            'tool_call_id': last_tool_call['id'],\n",
    "            'role': 'tool',\n",
    "            'name': last_tool_call['name'],\n",
    "            'content': review_data\n",
    "        }\n",
    "        \n",
    "        return Command(goto='agent', update={'messages': [updated_tool_message]})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29737144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "summarize_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    아래의 대화 이력을 요약해주세요.\n",
    "    만일 기존 요약 내용이 있다면, 해당 요약을 포함해 요약해주세요.\n",
    "    \n",
    "    [대화 이력]\n",
    "    {messages}\n",
    "    \n",
    "    [기존 요약]\n",
    "    {summary}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "def summarize(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    'summarize' Node\n",
    "    : 주어진 상태의 메시지를 요약한다.\n",
    "\n",
    "    Args:\n",
    "        - state(AgentState): 메시지 상태와 요약을 포함하는 state\n",
    "\n",
    "    Returns:\n",
    "        - AgentState: 응답 메시지를 포함하는 새로운 state\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = state['messages']\n",
    "    summary = state['summary']\n",
    "    \n",
    "    summarize_chain = summarize_prompt | llm | StrOutputParser()\n",
    "    ai_message = summarize_chain.invoke({'messages': messages, 'summary': summary})\n",
    "    \n",
    "    return {'summary': ai_message}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d9932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import RemoveMessage\n",
    "\n",
    "def delete(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    'delete' Node\n",
    "    : 주어진 상태에서 오래된 메시지를 삭제한다.\n",
    "\n",
    "    Args:\n",
    "        - state(AgentState): 메시지 상태와 요약을 포함하는 state\n",
    "\n",
    "    Returns:\n",
    "        - AgentState: 오래된 메시지가 삭제된 새로운 state\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = state['messages']\n",
    "    \n",
    "    return {'messages': [RemoveMessage(id=message.id) for message in messages[:-3]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e13e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    'agent' Node\n",
    "    : 주어진 상태에서 메시지를 가져와 LLM 및 도구를 사용하여 응답 메시지를 생성한다.\n",
    "\n",
    "    Args:\n",
    "        - state(AgentState): 메시지 상태와 요약을 포함하는 state\n",
    "\n",
    "    Returns:\n",
    "        - AgentState: 응답 메시지를 포함하는 새로운 state\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = state['messages']\n",
    "    summary = state['summary']\n",
    "    \n",
    "    if summary != '':\n",
    "        messages = [SystemMessage(content=f'Here is the summary of the earlier conversation: {summary}')] + messages\n",
    "    \n",
    "    ai_message = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    return {'messages': [ai_message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: AgentState) -> Literal['human_review', 'summarize']:\n",
    "    \"\"\"\n",
    "    주어진 state에 따라 다음 단계로 진행할지 결정한다.\n",
    "\n",
    "    Args:\n",
    "        - state(AgentState): 메시지와 도구 호출 정보를 포함하는 state\n",
    "\n",
    "    Returns:\n",
    "        - Literal['human_review', 'summarize']: 다음 단계로 'human_review' 또는 'summarize'를 반환\n",
    "    \"\"\"\n",
    "\n",
    "    messages = state['messages']\n",
    "    last_ai_message = messages[-1]\n",
    "\n",
    "    return 'human_review' if last_ai_message.tool_calls else 'summarize'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8030a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "# nodes\n",
    "graph_builder.add_node('agent', agent)\n",
    "graph_builder.add_node('tools', tool_node)\n",
    "graph_builder.add_node(human_review)\n",
    "graph_builder.add_node(summarize)\n",
    "graph_builder.add_node(delete)\n",
    "\n",
    "# edges\n",
    "graph_builder.add_edge(START, 'agent')\n",
    "graph_builder.add_conditional_edges(\n",
    "    'agent',\n",
    "    should_continue,\n",
    "    ['human_review', 'summarize'] \n",
    ")\n",
    "graph_builder.add_edge('tools', 'agent')\n",
    "graph_builder.add_edge('summarize', 'delete')\n",
    "graph_builder.add_edge('delete', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a30f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11a4c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fd825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"LLM Survey 논문의 내용을 검색해서 요약해주세요.\"\n",
    "config = {\n",
    "    'configurable': {\n",
    "        'thread_id': 'summarize_paper'\n",
    "    }\n",
    "}\n",
    "\n",
    "for chunk in graph.stream({'messages': [HumanMessage(query)], 'summary': ''}, config=config, stream_mode='values'):\n",
    "    chunk['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08224055",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = graph.stream(\n",
    "    input=Command(resume={\n",
    "        'action': 'update_args',\n",
    "        'data': {'query': 'Large Language Model: A Survey'}\n",
    "    }),\n",
    "    config=config,\n",
    "    stream_mode='updates'\n",
    ")\n",
    "\n",
    "for chunk in iter:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39944d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = graph.stream(\n",
    "    input=Command(resume={\n",
    "        'action': 'update_tool',\n",
    "        'data': 'arxiv가 아닌 Web으로 검색해주세요.'    \n",
    "    }),\n",
    "    config=config,\n",
    "    stream_mode='updates'\n",
    ")\n",
    "\n",
    "for chunk in iter:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d4cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(config).values['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e58835",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(config).values['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc18025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = graph.stream(\n",
    "    input=Command(resume={'action': 'continue'}),\n",
    "    config=config,\n",
    "    stream_mode='updates'\n",
    ")\n",
    "\n",
    "for chunk in iter:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f35beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(config).values['summary']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inflearn-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
