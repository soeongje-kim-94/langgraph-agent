{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9549c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9187d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e04b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool\n",
    "from langchain_community.agent_toolkits.polygon.toolkit import PolygonToolkit\n",
    "from langchain_community.utilities.polygon import PolygonAPIWrapper\n",
    "\n",
    "polygon = PolygonAPIWrapper()\n",
    "polygon_toolkit = PolygonToolkit.from_polygon_api_wrapper(polygon)\n",
    "polygon_tool_list = polygon_toolkit.get_tools()\n",
    "\n",
    "# market research tools\n",
    "market_research_tool_list = [YahooFinanceNewsTool()] + polygon_tool_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da00b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.types import Command\n",
    "\n",
    "market_research_agent = create_agent(\n",
    "    model=llm, \n",
    "    tools=market_research_tool_list,\n",
    "    system_prompt=\"You are a market researcher. Provide fact only not opinions.\"\n",
    ")\n",
    "\n",
    "def market_researcher(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n",
    "    \"\"\"\n",
    "    'market_researcher' Node\n",
    "    : 주어진 state를 기반으로 market_research agent를 호출하고, 결과를 supervisor node로 전달한다.\n",
    "\n",
    "    Args:\n",
    "        - state(MessagesState): 현재 메시지 상태를 나타내는 state\n",
    "\n",
    "    Returns:\n",
    "        - Command: supervisor node로 이동하기 위한 명령 반환\n",
    "    \"\"\"\n",
    "    \n",
    "    result = market_research_agent.invoke(state)\n",
    "    messages = result['messages']\n",
    "    \n",
    "    return Command(\n",
    "        update={'messages': [HumanMessage(content=messages[-1].content, name='market_research')]},\n",
    "        goto='supervisor'\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_stock_price(ticker: str) -> dict:\n",
    "    \"\"\"Given a stock ticker, return the price data for the past month\"\"\"\n",
    "    \n",
    "    return yf.download(ticker, period='1mo').to_dict()\n",
    "\n",
    "# stock research tools\n",
    "stock_research_tool_list = [get_stock_price]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f9075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_research_agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=stock_research_tool_list,\n",
    "    system_prompt=\"You are a stock researcher. Provide facts only not opinions.\"\n",
    ")\n",
    "\n",
    "def stock_researcher(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n",
    "    \"\"\"\n",
    "    'stock_researcher' Node\n",
    "    : 주어진 state를 기반으로 stock_research agent를 호출하고, 결과를 supervisor node로 전달한다.\n",
    "\n",
    "    Args:\n",
    "        - state(MessagesState): 현재 메시지 상태를 나타내는 state\n",
    "\n",
    "    Returns:\n",
    "        - Command: supervisor node로 이동하기 위한 명령 반환\n",
    "    \"\"\"\n",
    "    \n",
    "    result = stock_research_agent.invoke(state)\n",
    "    messages = result['messages']\n",
    "    \n",
    "    return Command(\n",
    "        update={'messages': [HumanMessage(content=messages[-1].content, name='stock_research')]},\n",
    "        goto='supervisor'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e27f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_company_info(ticker: str) -> dict:\n",
    "    \"\"\"Given a ticker, return the financial information and SEC filings\"\"\"\n",
    "    \n",
    "    company_info = yf.Ticker(ticker)\n",
    "    financial_info = company_info.get_financials()\n",
    "    sec_filings = company_info.get_sec_filings()\n",
    "    \n",
    "    return {\n",
    "        'financial_info': financial_info,\n",
    "        'sec_filings': sec_filings\n",
    "    }\n",
    "    \n",
    "# company research tools\n",
    "company_research_tool_list = [get_company_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c676f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_research_agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=company_research_tool_list,\n",
    "    system_prompt=\"You are a company researcher. Provide facts only not opinions.\"\n",
    ")\n",
    "\n",
    "def company_researcher(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n",
    "    \"\"\"\n",
    "    'company_researcher' Node\n",
    "    : 주어진 state를 기반으로 company_research agent를 호출하고, 결과를 supervisor node로 전달한다.\n",
    "\n",
    "    Args:\n",
    "        - state(MessagesState): 현재 메시지 상태를 나타내는 state\n",
    "\n",
    "    Returns:\n",
    "        - Command: supervisor node로 이동하기 위한 명령 반환\n",
    "    \"\"\"\n",
    "    \n",
    "    result = company_research_agent.invoke(state)\n",
    "    messages = result['messages']\n",
    "    \n",
    "    return Command(\n",
    "        update={'messages': [HumanMessage(content=messages[-1].content, name='company_research')]},\n",
    "        goto='supervisor'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74430e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "analyst_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a stock market analyst. Given the following information,\n",
    "    Please decide wheter to buy, sell, or hold the stock.\n",
    "    \n",
    "    [Information]\n",
    "    {messages}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "def analyst(state: MessagesState) -> MessagesState:\n",
    "    \"\"\"\n",
    "    'analyst' Node\n",
    "    : 주어진 state를 기반으로 투자 분석 체인을 호출하고, 응답 메시지를 반환한다.\n",
    "\n",
    "    Args:\n",
    "        - state(MessagesState): 현재 메시지 상태를 나타내는 state\n",
    "\n",
    "    Returns:\n",
    "        - MessagesState: 분석 결과 메시지를 포함하는 state\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = state['messages']\n",
    "    messages_without_system = messages[1:]\n",
    "    \n",
    "    analyst_chain = analyst_prompt | llm\n",
    "    ai_message = analyst_chain.invoke({'messages': messages_without_system})\n",
    "    \n",
    "    return {'messages': [ai_message]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeebe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "workers = [\"market_researcher\", \"stock_researcher\", \"company_researcher\"]\n",
    "options = workers + [\"FINISH\"]\n",
    "\n",
    "class Router(TypedDict):\n",
    "    \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "\n",
    "    next: Literal[*options]\n",
    "\n",
    "    \n",
    "llm_with_structured_output = llm.with_structured_output(Router)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d249e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor_system_prompt = f\"\"\"\n",
    "You are a supervisor tasked with managing a conversation between the following workers: {workers}.\n",
    "Given the following user request, respond with the worker to act next.\n",
    "Each worker will perform a task and respond with their results and status.\n",
    "When finished, respond with 'FINISH'.\n",
    "\"\"\"\n",
    "\n",
    "def supervisor(state: MessagesState) -> Command[Literal[*workers, 'analyst']]:\n",
    "    \"\"\"\n",
    "    'supervisor' Node\n",
    "    : 주어진 state를 기반으로 각 worker의 결과를 종합하고, 다음에 수행할 worker를 결정한다.\n",
    "    : 모든 작업이 완료되면, analyst node로 이동한다.\n",
    "\n",
    "    Args:\n",
    "        - state(MessagesState): 현재 메시지 상태를 나타내는 state\n",
    "\n",
    "    Returns:\n",
    "        - Command: 다음에 수행할 worker 또는 analyst node로 이동하기 위한 명령 반환\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    messages_with_system = [{\"role\": \"system\", \"content\": supervisor_system_prompt}] + messages\n",
    "    \n",
    "    # next\n",
    "    response = llm_with_structured_output.invoke(messages_with_system)\n",
    "    \n",
    "    if response[\"next\"] == 'FINISH':\n",
    "        return Command(goto='analyst')\n",
    "    \n",
    "    return Command(goto=response[\"next\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e9b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "\n",
    "# nodes\n",
    "graph_builder.add_node(supervisor)\n",
    "graph_builder.add_node(market_researcher)\n",
    "graph_builder.add_node(stock_researcher)\n",
    "graph_builder.add_node(company_researcher)\n",
    "graph_builder.add_node(analyst)\n",
    "\n",
    "# edges\n",
    "graph_builder.add_edge(START, 'supervisor')\n",
    "graph_builder.add_edge('analyst', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f40af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c351ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e7946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Would you invest in Snowflake?\"\n",
    "initial_state = {\"messages\": [(\"user\", query)]}\n",
    "\n",
    "for chunk in graph.stream(input=initial_state, stream_mode=\"values\"):\n",
    "    chunk['messages'][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inflearn-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
