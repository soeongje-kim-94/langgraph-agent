{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00de87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aa4a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0bd98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "\n",
    "from pyzerox import zerox\n",
    "\n",
    "# Model Setup (Use only Vision Models)\n",
    "# For other providers [https://docs.litellm.ai/docs/providers]\n",
    "\n",
    "# placeholder for additional model kwargs which might be required for some models\n",
    "kwargs = {}\n",
    "\n",
    "# system prompt to use for the vision model\n",
    "custom_system_prompt = None\n",
    "\n",
    "# to override\n",
    "# custom_system_prompt = \"For the below PDF page, do something..something...\"\n",
    "\n",
    "###################### OpenAI ######################\n",
    "model = \"gpt-4o-mini\"\n",
    "####################################################\n",
    "\n",
    "# Define main async entrypoint\n",
    "async def main():\n",
    "    file_path = \"/Users/ksj/MyProjects/llm/inflearn-langgrath-lecture/docs/income_tax.pdf\"\n",
    "    output_dir = \"/Users/ksj/MyProjects/llm/inflearn-langgrath-lecture/docs\"\n",
    "    \n",
    "    result = await zerox(\n",
    "        file_path=file_path,\n",
    "        model=model,\n",
    "        output_dir=output_dir,\n",
    "        custom_system_prompt=custom_system_prompt,\n",
    "        select_pages=None,\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# run the main function\n",
    "result = asyncio.run(main())\n",
    "\n",
    "# print markdown result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671d2477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "file_path_markdown = \"/Users/ksj/MyProjects/llm/inflearn-langgrath-lecture/docs/real_estate_tax.md\"\n",
    "file_path_text = \"/Users/ksj/MyProjects/llm/inflearn-langgrath-lecture/docs/real_estate_tax.txt\"\n",
    "\n",
    "# read the Markdown file\n",
    "with open(file_path_markdown, 'r', encoding='utf-8') as md_file:\n",
    "    md_content = md_file.read()\n",
    "\n",
    "# convert Markdown to HTML\n",
    "html_content = markdown.markdown(md_content)\n",
    "\n",
    "# use BeautifulSoup to extract text from HTML\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "text_content = soup.get_text()\n",
    "\n",
    "# save the text to .txt file\n",
    "with open(file_path_text, 'w', encoding='utf-8') as txt_file:\n",
    "    txt_file.write(text_content)\n",
    "\n",
    "print(\"Markdown converted to plain text successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d81b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd1a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 100,\n",
    "    separators=['\\n\\n', '\\n']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f48f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "loader = UnstructuredMarkdownLoader(file_path_markdown)\n",
    "documents = loader.load_and_split(text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828c81be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(file_path_text)\n",
    "documents = loader.load_and_split(text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b803a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    collection_name = 'real_estate_tax_collections',\n",
    "    persist_directory = './real_estate_tax_collections'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc574857",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={'k': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac11fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b232a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    'retrieve' Node\n",
    "    : 사용자의 질문에 기반하여, 벡터 스토어에서 관련 문서를 검색한다.\n",
    "\n",
    "    Args:\n",
    "        - state(AgentState): 사용자의 질문을 포함한 에이전트의 현재 state\n",
    "\n",
    "    Returns:\n",
    "        - AgentState: 검색된 문서가 추가된 state\n",
    "    \"\"\"\n",
    "    \n",
    "    query = state['query']\n",
    "    context = retriever.invoke(query)\n",
    "    \n",
    "    return {'context': context}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2571a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "prompt = client.pull_prompt(\"rlm/rag-prompt\", include_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ee0a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    'generate' Node\n",
    "    : 사용자의 질문과 검색된 문서를 기반으로 응답을 생성한다.\n",
    "\n",
    "    Args:\n",
    "        - state(AgentState): 사용자의 질문과 검색된 문서를 포함한 에이전트의 현재 state\n",
    "\n",
    "    Returns:\n",
    "        - AgentState: 생성된 응답이 추가된 state\n",
    "    \"\"\"\n",
    "    \n",
    "    query = state['query']\n",
    "    context = state['context']\n",
    "    \n",
    "    rag_chain = prompt | llm\n",
    "    ai_message = rag_chain.invoke({'question': query, 'context': context})\n",
    "    \n",
    "    return {'answer': ai_message}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "# nodes\n",
    "graph_builder.add_node('retrieve', retrieve)\n",
    "graph_builder.add_node('generate', generate)\n",
    "\n",
    "# edges\n",
    "graph_builder.add_edge(START, 'retrieve')\n",
    "graph_builder.add_edge('retrieve', 'generate')\n",
    "graph_builder.add_edge('generate', END)\n",
    "\n",
    "# sequence_graph_builder = StateGraph(AgentState).add_sequence([retrieve, generate])\n",
    "# sequence_graph_builder.add_edge(START, 'retrieve')\n",
    "# sequence_graph_builder.add_edge('generate', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843f95ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec338728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc782f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"연봉 5천만원인 거주자의 소득세는 얼마인가요?\"\n",
    "initial_state = {'query': query}\n",
    "\n",
    "graph.invoke(initial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inflearn-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
